
### RAG (Baseline):

Our baseline method features a **Retrieval-Augmented Generation (RAG)** pipeline, adapted to our project, to obtain answers from interview transcripts

- **Retriever**:
  The transcript is broken down into question-answer (QA) pairs. QA pairs as well as guideline questions are translated into embeddings using a pre-trained transformer model. These embeddings are compared using **cosine similarity**  to find the **top-k** (or **top-p**) most relevant matches.

- **Generator**:
  The relevant matches are sent to an LLM like **ChatGPT** as context, to extract the core meaning from the answers that are relevant to the guideline question. This setup **reduces hallucinated responses** by providing context to the LLM.

But RAG has drawbacks: if the information lies outside the top matches. The generator assumes
the relevance of retrieved content, at the risk of compromising accuracy.

### Self-RAG:

As a response to the vulnerability of Traditional RAG, **Self-RAG** has an additional self-evaluation layer with an LLM.

After it retrieves the **top-k QA pairs**, the LLM evaluates their relevance to the guideline question. If found relevant, pass along. If not, it adjusts **k** or **p** of the retriever, and attempts again. If it fails to retrieve any relevant content after multiple trials, it returns `[No relevant response found]`.

This auto-assessment cycle enhances accuracy and focus, particularly in situations where first-time retrievals are sub-optimal.