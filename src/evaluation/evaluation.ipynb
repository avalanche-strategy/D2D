{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abcae655",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import os  \n",
    "import re\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62731c13-755c-47e0-b132-1bf0c413000e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_rag</th>\n",
       "      <th>answer_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>Hey, what’s the biggest news story or issue yo...</td>\n",
       "      <td>the upcoming election</td>\n",
       "      <td>The upcoming election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>Can you tell me more about that news story? Wh...</td>\n",
       "      <td>it’s a woman Kamala against Donald Trump; hear...</td>\n",
       "      <td>It is a woman Kamala against Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>So, why does that event or issue feel like the...</td>\n",
       "      <td>best president for our country</td>\n",
       "      <td>It’s important we chose the best president for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>You mentioned you feel like you can help make ...</td>\n",
       "      <td>if grownups and kids listened and tried to be ...</td>\n",
       "      <td>I think if we talked to each other more and ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>What are you thinking of dressing up as for Ha...</td>\n",
       "      <td>Briar Rose and Lydia.</td>\n",
       "      <td>Briar Rose | Lydia |</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          respondent_id  \\\n",
       "0  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "1  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "2  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "3  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "4  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "\n",
       "                                            question  \\\n",
       "0  Hey, what’s the biggest news story or issue yo...   \n",
       "1  Can you tell me more about that news story? Wh...   \n",
       "2  So, why does that event or issue feel like the...   \n",
       "3  You mentioned you feel like you can help make ...   \n",
       "4  What are you thinking of dressing up as for Ha...   \n",
       "\n",
       "                                          answer_rag  \\\n",
       "0                              the upcoming election   \n",
       "1  it’s a woman Kamala against Donald Trump; hear...   \n",
       "2                     best president for our country   \n",
       "3  if grownups and kids listened and tried to be ...   \n",
       "4                              Briar Rose and Lydia.   \n",
       "\n",
       "                                          answer_ref  \n",
       "0                              The upcoming election  \n",
       "1          It is a woman Kamala against Donald Trump  \n",
       "2  It’s important we chose the best president for...  \n",
       "3  I think if we talked to each other more and ar...  \n",
       "4                              Briar Rose | Lydia |   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load files\n",
    "rag_df = pd.read_csv(\"../../data/evaluation_input/small_sample/answer_1090.csv\")\n",
    "ref_df = pd.read_csv(\"../../data/evaluation_input/small_sample/reference_answer_1090.csv\")\n",
    "\n",
    "# Clean column names\n",
    "rag_df.columns = rag_df.columns.str.strip()\n",
    "ref_df.columns = ref_df.columns.str.strip()\n",
    "\n",
    "# Rename respondent column to be consistent\n",
    "rag_df = rag_df.rename(columns={\"Interview File\": \"respondent_id\"})\n",
    "ref_df = ref_df.rename(columns={\"respondent_id\": \"respondent_id\"})\n",
    "\n",
    "# Melt both to long format\n",
    "rag_long = rag_df.melt(id_vars=[\"respondent_id\"], var_name=\"question\", value_name=\"answer_rag\")\n",
    "ref_long = ref_df.melt(id_vars=[\"respondent_id\"], var_name=\"question\", value_name=\"answer_ref\")\n",
    "\n",
    "# Merge them\n",
    "merged_df = pd.merge(rag_long, ref_long, on=[\"respondent_id\", \"question\"], how=\"left\")\n",
    "\n",
    "# Remove rows without answer\n",
    "merged_df = merged_df.dropna(subset=[\"answer_rag\"])\n",
    "\n",
    "# Define GPT-based evaluation\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Optional: check structure\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6541607-2ff0-49a7-85ac-9dd94bac02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_score_and_feedback(prompt: str, temperature: float = 0.0, model: str = \"gpt-4o-mini\") -> tuple[float, str]:\n",
    "    \"\"\"\n",
    "    Ask GPT to return a numeric score and feedback using a structured format.\n",
    "    Expected LLM format:\n",
    "        Score: <number>\n",
    "        Feedback: <text>\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The instruction sent to GPT.\n",
    "    - temperature (float): Temperature setting for response.\n",
    "    - model (str): GPT model to use.\n",
    "\n",
    "    Returns:\n",
    "    - (score, feedback): float score and string feedback. If parsing fails, score is np.nan.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful evaluation assistant. Respond in this format:\\nScore: <number>\\nFeedback: <short explanation>\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Match flexible \"Score: X\" and \"Feedback: ...\"\n",
    "        match = re.search(\n",
    "            r\"Score\\s*[:：]\\s*([0-9.]+)\\s*[\\n\\r]+Feedback\\s*[:：]\\s*(.*)\",\n",
    "            content,\n",
    "            re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "\n",
    "        if match:\n",
    "            score = float(match.group(1).strip())\n",
    "            feedback = match.group(2).strip()\n",
    "        else:\n",
    "            # fallback if format is not matched\n",
    "            score = np.nan\n",
    "            feedback = content\n",
    "\n",
    "    except Exception as e:\n",
    "        score = np.nan\n",
    "        feedback = f\"Error calling OpenAI: {e}\"\n",
    "\n",
    "    return score, feedback\n",
    "    \n",
    "\n",
    "def build_prompt(metric: str, row: dict) -> str:\n",
    "    question = row[\"question\"]\n",
    "    answer = row[\"answer_rag\"]\n",
    "    context = row.get(\"retrieved_context\", \"\")\n",
    "    reference = row.get(\"answer_ref\", \"\")\n",
    "\n",
    "    if metric == \"relevance\":\n",
    "        return f\"\"\"Evaluate the relevance of the answer to the question.\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "First, rate from 1 (not relevant) to 5 (fully relevant).\n",
    "Then explain briefly.\n",
    "Respond in the format:\n",
    "Score: X\n",
    "Feedback: ...\"\"\"\n",
    "\n",
    "    elif metric == \"faithfulness\":\n",
    "        return f\"\"\"Evaluate the faithfulness of the answer to the retrieved context.\n",
    "Context: {context}\n",
    "Answer: {answer}\n",
    "Rate from 1 (hallucinated) to 5 (fully grounded), then explain.\n",
    "Respond in the format:\n",
    "Score: X\n",
    "Feedback: ...\"\"\"\n",
    "\n",
    "    elif metric == \"precision\":\n",
    "        return f\"\"\"Evaluate whether the context includes only necessary info to generate the answer.\n",
    "Context: {context}\n",
    "Answer: {answer}\n",
    "Rate from 1 (verbose) to 5 (precise), then explain.\n",
    "Respond in the format:\n",
    "Score: X\n",
    "Feedback: ...\"\"\"\n",
    "\n",
    "    elif metric == \"recall\":\n",
    "        return f\"\"\"Evaluate whether the context includes all necessary info to answer the question.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer: {answer}\n",
    "Rate from 1 (missing info) to 5 (complete), then explain.\n",
    "Respond in the format:\n",
    "Score: X\n",
    "Feedback: ...\"\"\"\n",
    "\n",
    "    elif metric == \"correctness\":\n",
    "        return f\"\"\"Compare the generated answer with the reference.\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "Reference: {reference}\n",
    "Rate from 1 (wrong) to 5 (semantically equivalent), then explain.\n",
    "Respond in the format:\n",
    "Score: X\n",
    "Feedback: ...\"\"\"\n",
    "\n",
    "    elif metric == \"consistency\":\n",
    "        return f\"\"\"Evaluate the structural and stylistic consistency of the answer.\n",
    "Answer: {answer}\n",
    "Rate from 1 (unclear or inconsistent) to 5 (clear and well-structured), then explain.\n",
    "Respond in the format:\n",
    "Score: X\n",
    "Feedback: ...\"\"\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown metric: {metric}\")\n",
    "    \n",
    "\n",
    "def score_ragas(row: pd.Series) -> pd.Series:\n",
    "    metrics = []\n",
    "    if pd.notna(row.get(\"retrieved_context\")):\n",
    "        metrics += [\"faithfulness\", \"precision\", \"recall\"]\n",
    "    metrics += [\"relevance\", \"consistency\"]\n",
    "    if pd.notna(row.get(\"answer_ref\")):\n",
    "        metrics.append(\"correctness\")\n",
    "\n",
    "    results = {}\n",
    "    for metric in metrics:\n",
    "        prompt = build_prompt(metric, row)\n",
    "        score, feedback = ask_score_and_feedback(prompt)\n",
    "        results[f\"{metric}_score\"] = score\n",
    "        results[f\"{metric}_feedback\"] = feedback\n",
    "\n",
    "    return pd.Series(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82b8aa9b-c2eb-45a4-a17d-0c2ee8af5a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [00:37<00:00,  4.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_rag</th>\n",
       "      <th>answer_ref</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>relevance_feedback</th>\n",
       "      <th>consistency_score</th>\n",
       "      <th>consistency_feedback</th>\n",
       "      <th>correctness_score</th>\n",
       "      <th>correctness_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>Hey, what’s the biggest news story or issue yo...</td>\n",
       "      <td>the upcoming election</td>\n",
       "      <td>The upcoming election</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The answer is relevant as it addresses a signi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The answer is vague and lacks context, making ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The generated answer is semantically equivalen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>Can you tell me more about that news story? Wh...</td>\n",
       "      <td>it’s a woman Kamala against Donald Trump; hear...</td>\n",
       "      <td>It is a woman Kamala against Donald Trump</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The answer provides relevant information about...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The answer presents a clear subject (Kamala ag...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The generated answer provides some relevant in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>So, why does that event or issue feel like the...</td>\n",
       "      <td>best president for our country</td>\n",
       "      <td>It’s important we chose the best president for...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The answer does not directly address the quest...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The answer is vague and lacks clarity, making ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The generated answer and the reference both ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>You mentioned you feel like you can help make ...</td>\n",
       "      <td>if grownups and kids listened and tried to be ...</td>\n",
       "      <td>I think if we talked to each other more and ar...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The answer touches on the importance of kindne...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The answer is clear and conveys a straightforw...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Both answers emphasize the importance of kindn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>What are you thinking of dressing up as for Ha...</td>\n",
       "      <td>Briar Rose and Lydia.</td>\n",
       "      <td>Briar Rose | Lydia |</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The answer directly addresses the question by ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The answer is unclear and lacks context, makin...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The answer directly lists the same characters ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>When you’re out trick-or-treating, what’s the ...</td>\n",
       "      <td>Hershey bars, like the full-size ones.</td>\n",
       "      <td>Hershey bars</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The answer directly addresses the question by ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The answer is unclear and lacks context, makin...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The generated answer is semantically equivalen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>On the flip side, what’s the worst thing someo...</td>\n",
       "      <td>Twizzlers.</td>\n",
       "      <td>Twizzlers</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The answer is relevant as it directly addresse...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The answer \"Twizzlers\" is unclear and lacks co...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The generated answer is semantically equivalen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>You said you’re planning to watch something Ha...</td>\n",
       "      <td>Beetlejuice and Nightmare Before Christmas.</td>\n",
       "      <td>Beetlejuice and Nightmare before Christmas</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The answer directly addresses the question by ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The answer lacks clarity and context, as it si...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The generated answer is semantically equivalen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c7d7640b-9344-48aa-9d48-7395eaeda149</td>\n",
       "      <td>Tell me everything about how you feel about Ha...</td>\n",
       "      <td>Excited to wear my costume, go trick or treati...</td>\n",
       "      <td>I’m excited to wear my costume to school and a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The answer directly addresses the question by ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The answer is clear and conveys excitement eff...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The generated answer captures the excitement f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          respondent_id  \\\n",
       "0  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "1  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "2  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "3  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "4  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "5  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "6  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "7  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "8  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
       "\n",
       "                                            question  \\\n",
       "0  Hey, what’s the biggest news story or issue yo...   \n",
       "1  Can you tell me more about that news story? Wh...   \n",
       "2  So, why does that event or issue feel like the...   \n",
       "3  You mentioned you feel like you can help make ...   \n",
       "4  What are you thinking of dressing up as for Ha...   \n",
       "5  When you’re out trick-or-treating, what’s the ...   \n",
       "6  On the flip side, what’s the worst thing someo...   \n",
       "7  You said you’re planning to watch something Ha...   \n",
       "8  Tell me everything about how you feel about Ha...   \n",
       "\n",
       "                                          answer_rag  \\\n",
       "0                              the upcoming election   \n",
       "1  it’s a woman Kamala against Donald Trump; hear...   \n",
       "2                     best president for our country   \n",
       "3  if grownups and kids listened and tried to be ...   \n",
       "4                              Briar Rose and Lydia.   \n",
       "5             Hershey bars, like the full-size ones.   \n",
       "6                                         Twizzlers.   \n",
       "7        Beetlejuice and Nightmare Before Christmas.   \n",
       "8  Excited to wear my costume, go trick or treati...   \n",
       "\n",
       "                                          answer_ref  relevance_score  \\\n",
       "0                              The upcoming election              4.0   \n",
       "1          It is a woman Kamala against Donald Trump              4.0   \n",
       "2  It’s important we chose the best president for...              2.0   \n",
       "3  I think if we talked to each other more and ar...              3.0   \n",
       "4                              Briar Rose | Lydia |               5.0   \n",
       "5                                       Hershey bars              5.0   \n",
       "6                                          Twizzlers              4.0   \n",
       "7         Beetlejuice and Nightmare before Christmas              5.0   \n",
       "8  I’m excited to wear my costume to school and a...              5.0   \n",
       "\n",
       "                                  relevance_feedback  consistency_score  \\\n",
       "0  The answer is relevant as it addresses a signi...                2.0   \n",
       "1  The answer provides relevant information about...                3.0   \n",
       "2  The answer does not directly address the quest...                2.0   \n",
       "3  The answer touches on the importance of kindne...                4.0   \n",
       "4  The answer directly addresses the question by ...                2.0   \n",
       "5  The answer directly addresses the question by ...                2.0   \n",
       "6  The answer is relevant as it directly addresse...                1.0   \n",
       "7  The answer directly addresses the question by ...                2.0   \n",
       "8  The answer directly addresses the question by ...                4.0   \n",
       "\n",
       "                                consistency_feedback  correctness_score  \\\n",
       "0  The answer is vague and lacks context, making ...                5.0   \n",
       "1  The answer presents a clear subject (Kamala ag...                3.0   \n",
       "2  The answer is vague and lacks clarity, making ...                3.0   \n",
       "3  The answer is clear and conveys a straightforw...                3.0   \n",
       "4  The answer is unclear and lacks context, makin...                5.0   \n",
       "5  The answer is unclear and lacks context, makin...                5.0   \n",
       "6  The answer \"Twizzlers\" is unclear and lacks co...                5.0   \n",
       "7  The answer lacks clarity and context, as it si...                5.0   \n",
       "8  The answer is clear and conveys excitement eff...                4.0   \n",
       "\n",
       "                                correctness_feedback  \n",
       "0  The generated answer is semantically equivalen...  \n",
       "1  The generated answer provides some relevant in...  \n",
       "2  The generated answer and the reference both ex...  \n",
       "3  Both answers emphasize the importance of kindn...  \n",
       "4  The answer directly lists the same characters ...  \n",
       "5  The generated answer is semantically equivalen...  \n",
       "6  The generated answer is semantically equivalen...  \n",
       "7  The generated answer is semantically equivalen...  \n",
       "8  The generated answer captures the excitement f...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply evaluation\n",
    "tqdm.pandas()\n",
    "scores_df = merged_df.progress_apply(score_ragas, axis=1)\n",
    "\n",
    "# Combine results\n",
    "result_df = pd.concat([merged_df, scores_df], axis=1)\n",
    "\n",
    "# Optional: save to CSV\n",
    "# result_df.to_csv(\"ragas_evaluation_result.csv\", index=False)\n",
    "\n",
    "# Display results\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:D2D] *",
   "language": "python",
   "name": "conda-env-D2D-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
