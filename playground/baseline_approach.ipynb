{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eaede86-d054-4083-be93-6db4c793e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Modular Functions\n",
    "def load_guidelines(guidelines_path):\n",
    "    \"\"\"Load discussion guide questions from a CSV file.\"\"\"\n",
    "    guidelines = pd.read_csv(guidelines_path)\n",
    "    return guidelines[\"guide_text\"].tolist()\n",
    "\n",
    "def load_transcript(transcript_path):\n",
    "    \"\"\"Load a transcript file into a string.\"\"\"\n",
    "    with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def segment_transcript(transcript, nlp):\n",
    "    \"\"\"Group interviewer and interviewee turns into question-response pairs.\"\"\"\n",
    "    doc = nlp(transcript)\n",
    "    groups = []\n",
    "    current_group = {\"interviewer\": [], \"interviewee\": []}\n",
    "    current_speaker = None\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        sent_text = sent.text.strip()\n",
    "        if sent_text.startswith(\"Interviewer:\"):\n",
    "            if current_group[\"interviewer\"] or current_group[\"interviewee\"]:\n",
    "                groups.append(current_group)\n",
    "                current_group = {\"interviewer\": [], \"interviewee\": []}\n",
    "            current_speaker = \"Interviewer\"\n",
    "            current_group[\"interviewer\"].append(sent_text)\n",
    "        elif sent_text.startswith(\"Interviewee:\"):\n",
    "            current_speaker = \"Interviewee\"\n",
    "            current_group[\"interviewee\"].append(sent_text)\n",
    "        elif current_speaker:\n",
    "            current_group[current_speaker.lower()].append(sent_text)\n",
    "\n",
    "    if current_group[\"interviewer\"] or current_group[\"interviewee\"]:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    return [g for g in groups if g[\"interviewer\"] and g[\"interviewee\"]]\n",
    "\n",
    "def match_responses(groups, guide_questions, model, device, confidence_threshold=0.5):\n",
    "    \"\"\"Match interviewee responses to guide questions based on interviewer questions.\"\"\"\n",
    "    matches = []\n",
    "    for group in groups:\n",
    "        interviewer_question = \" \".join(group[\"interviewer\"]).replace(\"Interviewer: \", \"\")\n",
    "        interviewee_response = \" \".join(group[\"interviewee\"]).replace(\"Interviewee: \", \"\")\n",
    "        \n",
    "        question_embedding = model.encode(interviewer_question, convert_to_tensor=True, device=device)\n",
    "        guide_embeddings = model.encode(guide_questions, convert_to_tensor=True, device=device)\n",
    "        \n",
    "        similarities = util.cos_sim(question_embedding, guide_embeddings)[0].cpu().numpy()\n",
    "        best_question_idx = np.argmax(similarities)\n",
    "        best_similarity = similarities[best_question_idx]\n",
    "        \n",
    "        matches.append({\n",
    "            \"response\": interviewee_response,\n",
    "            \"question\": guide_questions[best_question_idx],\n",
    "            \"similarity\": float(best_similarity),\n",
    "            \"is_uncertain\": best_similarity < confidence_threshold\n",
    "        })\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def generate_output(interview_files, matches_list, guide_questions):\n",
    "    \"\"\"Generate a structured CSV with one row per interview and columns for guide questions.\"\"\"\n",
    "    output_data = []\n",
    "    for file_path, matches in zip(interview_files, matches_list):\n",
    "        file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        row = {\"Interview File\": file_name}\n",
    "        \n",
    "        # Initialize all question columns with empty strings\n",
    "        for question in guide_questions:\n",
    "            row[question] = \"\"\n",
    "        \n",
    "        # Populate matched responses\n",
    "        for match in matches:\n",
    "            if not match[\"is_uncertain\"]:  # Only include confident matches\n",
    "                row[match[\"question\"]] = match[\"response\"]\n",
    "        \n",
    "        output_data.append(row)\n",
    "    \n",
    "    output_df = pd.DataFrame(output_data)\n",
    "    output_df.to_csv(\"matched_interviews.csv\", index=False)\n",
    "    print(\"Output saved to matched_interviews.csv\")\n",
    "    print(output_df[[\"Interview File\"] + guide_questions[:2]])  # Print subset for brevity\n",
    "\n",
    "# Main Execution\n",
    "def main(transcript_dir, guidelines_path):\n",
    "    # Initialize NLP tools\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    device = torch.device(\"cpu\")  # Use CPU to avoid MPS issues\n",
    "    \n",
    "    # Load guidelines\n",
    "    guide_questions = load_guidelines(guidelines_path)\n",
    "    \n",
    "    # Load all transcript files\n",
    "    transcript_files = glob(os.path.join(transcript_dir, \"*.txt\"))\n",
    "    if not transcript_files:\n",
    "        raise FileNotFoundError(\"No transcript files found in directory\")\n",
    "    \n",
    "    matches_list = []\n",
    "    for transcript_path in transcript_files:\n",
    "        # Load and segment transcript\n",
    "        transcript = load_transcript(transcript_path)\n",
    "        groups = segment_transcript(transcript, nlp)\n",
    "        \n",
    "        # Match responses\n",
    "        matches = match_responses(groups, guide_questions, model, device)\n",
    "        matches_list.append(matches)\n",
    "    \n",
    "    # Generate output\n",
    "    generate_output(transcript_files, matches_list, guide_questions)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     transcript_dir = \"data/synthetic_data/\"\n",
    "#     guidelines_path = \"data/synthetic_data/interview_518_guidelines.csv\"\n",
    "#     main(transcript_dir, guidelines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9c6dbf-0c25-4f7f-8a6f-94786e8e1bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to matched_interviews.csv\n",
      "                         Interview File  \\\n",
      "0  c7d7640b-9344-48aa-9d48-7395eaeda149   \n",
      "1  387bf5f4-4944-4247-9980-d69983b44a6f   \n",
      "2  6c8cf423-2a8d-4a67-9133-c1c34e3ee04f   \n",
      "3  f405a20e-d532-4abc-a197-8099f2270344   \n",
      "4  7b18e570-043a-4b9d-8e6a-5880c770e96b   \n",
      "5  fe189a48-e69d-4c97-b004-b25789b1f63d   \n",
      "6  ea99ab44-c149-4919-9601-7d6c013af9c2   \n",
      "7  fbfe46f7-24aa-465c-a744-587f472077a7   \n",
      "8  57b45fe6-c016-4e1d-aef6-d50309d92c17   \n",
      "9  19ab5410-a614-4a1b-99ca-f15ad467cb54   \n",
      "\n",
      "  Hey, what’s the biggest news story or issue you’ve heard about lately?  \\\n",
      "0  Um, well, the upcoming election. That’s what e...                       \n",
      "1  Yeah, actually, there was this thing about soc...                       \n",
      "2  Yeah, for sure. The thing I keep hearing about...                       \n",
      "3  I mean, it’s surprising, but also kind of sad,...                       \n",
      "4  Uh, yeah, there is a election. And if Trump ve...                       \n",
      "5  Uh, yeah, so, the shootings at schools. That's...                       \n",
      "6  Oh, yeah, so I heard that Donald Trump got sho...                       \n",
      "7                                                                          \n",
      "8                                                                          \n",
      "9  Um, yeah, so I think the hurricane in Florida?...                       \n",
      "\n",
      "  Can you tell me more about that news story? What have you heard about it, where did you hear it, and how do you feel about it?  \n",
      "0  It’s, um, a woman Kamala against Donald Trump....                                                                              \n",
      "1  Sure. So, someone said they were going to shoo...                                                                              \n",
      "2                                                                                                                                 \n",
      "3                                                                                                                                 \n",
      "4                                                                                                                                 \n",
      "5  My school said there were threats made to shoo...                                                                              \n",
      "6  I know he got shot in the ear at a press confe...                                                                              \n",
      "7                                                                                                                                 \n",
      "8                                                                                                                                 \n",
      "9  So, I’m actually from there, which is why it s...                                                                              \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_directory = \"../data/private_data/\"\n",
    "interview_name = \"interview_1090\"\n",
    "interviews_directory = data_directory + interview_name + \"/\"\n",
    "guidelines_path = data_directory + interview_name + \"_guidelines.csv\"\n",
    "main(interviews_directory, guidelines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1e76d-5685-4196-9de7-08711201ee04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:575] *",
   "language": "python",
   "name": "conda-env-575-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
